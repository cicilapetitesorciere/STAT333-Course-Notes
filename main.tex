\documentclass{report}

\usepackage{tcolorbox}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{svg}
\usepackage{tabularx}

\usepackage{nicefrac}



\begin{document}

\setlength\parindent{0pt}

\newcommand{\todo}{TODO\quad}

\newtcolorbox[auto counter,number within=section]{example}[2][]{%
    colback=green!5!white,
    colframe=green!75!black,
    fonttitle=\bfseries,
    title=Example.~\thetcbcounter: #2
}

\newtcolorbox[auto counter,number within=section]{definition}[2][]{%
    colback=blue!5!white,
    colframe=blue!75!black,
    fonttitle=\bfseries,
    title=Definition~\thetcbcounter: #2
}

\newtcolorbox[auto counter,number within=section]{theorem}[2][]{%
    colback=yellow!5!white,
    colframe=yellow!75!black,
    fonttitle=\bfseries,
    title=Theorem~\thetcbcounter: #2
}

\newtcolorbox[auto counter,number within=section]{lemma}[1][]{%
    colback=yellow!5!white,
    colframe=yellow!75!black,
    fonttitle=\bfseries,
    title=Lemma~\thetcbcounter
}

\newtcolorbox[auto counter,number within=section]{notsofast}[1][]{%
    colback=red!5!white,
    colframe=red!75!black,
    fonttitle=\bfseries,
    title=\emph{Not So Fast!}
}

\tableofcontents

\chapter{Univariate Distributions and Generating Functions}

\section{Laws of Probability}
Imagine you have have a coin and you flip it twice in a row. One of several things may happen. Perhaps you get two heads ($HH$), or two tails ($TT$), or perhaps some combination of the two ($HT$ or $TH$). We can list all the possibilities of what might happen, \emph{however} we do not know what \emph{will} happen. We will observe many situations like this this course and in real life, and we refer to them as \textbf{Random Experiments}. The \textbf{Sample Space} of a Random Experiment (often denoted as $S$ or $\Omega$) is the set of all possible outcomes we may observe. For instance:
\[
    \Omega=\{HH,HT,TH,TT\}
\]

\begin{notsofast}
The Sample Space is not unique! We may define it differently depending on what properties we are interested in. For instance, suppose we do not care about the order of the coins but simply how many heads we observe. In this case we could define the Sample Space as
\[
    \Omega=\{0,1,2\}
\]
which is equally valid.
\end{notsofast}
We may also be interested in certain subsets of the Sample Space. For instance: what are the different ways we can get the same coin twice?
\[
    \{HH,TT\}\subseteq \Omega
\]
We refer to such subsets as \textbf{Events}. For the purposes of this course, any subset of the Sample Space can be considered an Event (\todo CONFIRM!). Any two Events $A$ and $B$ are \textbf{Mutually Exclusive} if $A\cup B=\emptyset$. From here we get the definition of \textbf{Probability}:
\begin{definition}{Probability}
Probability is a function which maps Events to $\mathbb R$ and satisfies the following axioms:
\begin{enumerate}
    \item 
    \begin{enumerate}
        \item $P(\emptyset) = 0$
        \item $P(\Omega)=1$
    \end{enumerate}
    \item If $A_1, A_2,...$ are Mutually Exclusive Events, then
    \[
        P\left(\ \bigcup_{i=1}^\infty A_i\ \right) = \sum_{i=1}^\infty P(A_i)
    \]
\end{enumerate}
\end{definition}
\label{def:probability}
From this one small definition, we can derive the entire field of probability theory, including the following lemmas:

\begin{lemma}
    For any Event $A$ with compliment $\bar A$, $P(\bar A)=1-P(A)$
\tcblower
\begin{proof}
    Since $A$ and $\bar A$ are compliments of one another, they are mutually exclusive and satisfy
    \[
        A\cup \bar A = \Omega
    \]
    and hence
    \[
        P(A)+P(\bar A) = P(\Omega) = 1
    \]
    giving us
    \[
        P(\bar A)=1-P(A)
    \]
\end{proof}
\end{lemma}

\begin{lemma}
    For any two Events $A$ and $B$ such that $A\subseteq B$, $P(A)\le P(B)$.
    \tcblower
    \begin{proof}
    Consider the Event $B\backslash A$, which is mutually exclusive to $A$. Since $A\subseteq B$ we may express $B$ as
    \[
        B=A\cup (B\backslash A)
    \]
    giving us
    \[
        P(B)=P(A)+P(B\backslash A)
    \]
    It can be shown that the probability of any Event is greater than or equal to zero (this is left as an exercise to the reader), and therefore $P(B)\le P(A)$.
    \end{proof}
\end{lemma}

One special case of Definition \ref{def:probability} is known as \textbf{The Classical Definition of Probability}. \todo CLASSICAL DEFINITION

\subsection*{End-of-the-section Problems}\label{sec:problaw_eosp}

\begin{enumerate}
    \item Which of the following has the highest probability?
    \begin{enumerate}
        \item Observing at least one six in 6 rolls of a fair die
        \item At least two sixes in 12 rolls of a fair die
        \item At least three sixes in 18 rolls of a fair die
    \end{enumerate}
    \item Suppose $n$ random strangers meet at a party. Assuming all birthdays are equally likely (and ignoring leap years, twins, etc.) show that if $n\ge 23$ then the probability of two people sharing the same birthday is greater than \nicefrac 12.
    \item Suppose two fair dice are rolled. What is the probability of getting at least one six?
    \item\textbf{(The Secretary's Problem)}
    Suppose you have applied to three jobs and are waiting to hear back. You are pretty sure that all three companies will give you an offer, but you do not know what salary they will offer you. And after each company presents their offer, you will have to decide whether to accept or reject it, and will not have time wait around to see what the next company is planning to offer you. What is the optimal strategy for maximizing your chances of accepting the best offer?
    \item \textbf{(DeMontfort's Problem)} 
    \begin{enumerate}
        \item Suppose you have 4 envelopes and 4 letters which you place in the envelopes at random such that each envelope contains exactly one letter. Find the probability that at least one of of the 4 letters ends up in the correct envelope.
        \item Find the general solution for $n$ letters and $n$ envelopes, and show what happens when $n\to\infty$.
    \end{enumerate}
    \item \textbf{(Simpson's Paradox)} Suppose we have two doctors (we will call them Dr. Bart and Dr. Lisa) each performing two operations (for instance: neurosurgery and bandaging a wound). Both doctors perform each surgery with some success rate. Now here's the riddle: is it possible that Dr. Lisa is better than Dr. Bart at both neurosurgery and bandaging, and yet have a lower overall success-rate? How might this strategy generalize to $n$ offers.
\end{enumerate}

\section{Conditional Probability}
Let $A$ and $B$ be two Events. Then the probability of $A$ given that $B$ has occurred, denoted b y $P(A\vert B)$ is given by
\[
    P(A\vert B)=\frac{P(A\cap B)}{P(B)}
\]
We often call $P(A)$ the \textbf{Prior Probability} and $P(A\vert B)$ the \textbf{Posterior Probability}.
\begin{notsofast}
    A common mistake is to assume that $P(A\vert B)=P(B\vert A)$, however this is not the case. This mistake is often known as ``the Prosecutor's Fallacy". We will discuss the high-profile case from where this name originated later in the section.
\end{notsofast}

\begin{figure}
    \centering
    \includesvg{figures/dependence.svg}
    \caption{An illustration of Conditional Probability. The Prior Probability $P(A)$ is $\nicefrac 5{10}$, however the Posterior Probability $P(A|B)$ is $\nicefrac 35$}
    \label{fig:dependence}
\end{figure}

\subsection{LOTP and Bayes Rule}
The definition of $P(A\vert B)$ is deceptively simple, but it has wide-ranging consequences. But first, we must establish yet more terminology: A \textbf{Partition} of $\Omega$ is any set of Mutually Exclusive Events $B_1,B_2,...,B_n$ such that $B_1\cup B_2\cup\cdots \cup B_n=\Omega$.

\begin{theorem}{Law of Total Probability (LOTP)}
Let $B_1,B_2,...,B_n$ be some Partition of $\Omega$. Then for any Event $A$
\[
    P(A)=\sum_{i=1}^n P(A\vert B_i) P(B_i)
\]
\tcblower
\begin{proof}
    Since $B_1,B_2,...,B_n$ form a Partition of $\Omega$, we can decompose $A$ into the following union of Mutually Exclusive Events:
    \[
        A=(A\cap B_1)\cup (A\cap B_2) \cup \cdots \cup (A\cap B_n)
    \]
    \begin{center}
        \includesvg{figures/lotp.svg}
    \end{center}
    Then by Definition \ref{def:probability}
    \[
        P(A)=P(A\cap B_1)+ P(A\cap B_2)+ \cdots + P(A\cap B_n)
    \]
\end{proof}
\end{theorem}

\begin{example}{The Unfair Coin}
    Suppose you have two coins. One is fair, whereas the other one has $P(H)=\nicefrac 34$. One coin is picked at random and tossed 3 times. Find the probability that all three tosses return \emph{Heads}.
\tcblower
Let $F$ be the Event that a fair coin is chosen out of the two, and let $H^3$ be the probability of observing 3 heads. If we assume that there is an equal chance of choosing each coin, then the Prior Probability of observing $F$ and $\bar F$ are $P(F)=P(\bar F)=\nicefrac 12$, and the Posterior Probabilities of $H^3$ are
\[
    P(H^3 | F) = \left(\frac 12\right)^3;\quad P(H^3 | \bar F) = \left(\frac 34\right)^3
\]
Since $F$ and $\bar F$ are a Partition of the Sample Space, we may then use the Law of Total Probability to find
\[
    P(H^3) = P(H^3|F)P(F)+P(H^3|\bar F)P(\bar F)= \left(\frac 12\right)^3\times \frac 12 + \left(\frac 34\right)^3\times\frac 12
\]
or around $27\%$.
\end{example}
    

\begin{theorem}{Bayes Rule}
    Let $B_1,B_2,...,B_n$ be some Partition of $\Omega$. Then for any Event $A$ and any $i\in \{1,2,...,n\}$:
    \[
        P(B_i\vert A) = \frac{P(A\vert B_i)P(B_i)}{P(A)}
    \]
    or equivalently, using the Law of Total Probability
    \[
        P(B_i\vert A) = \frac{P(A\vert B_i)P(B_i)}{\sum_{i=j}^n P(A|B_j)P(B_j)}
    \]
    \tcblower
    The proof of this is left as an exercise to the reader. 
\end{theorem}

\begin{example}{The Unfair Coin Revisited}
    Suppose you have two coins. One is fair, whereas the other one has $P(H)=\nicefrac 34$. You pick one coin at random and flip it three times. All three tosses turn up heads. What is the probability that the fair coin was chosen?
\tcblower
    We are trying to find $P(F|H^3)$. By Bayes Rule
    \[
        P(F | H^3) = \frac {P(H^3| F)P(F)}{P(H^3)} = \frac{(\nicefrac 12)^3\times \nicefrac 12}{\left(\nicefrac 12\right)^3\times \nicefrac 12 + \left(\nicefrac 34\right)^3\times\nicefrac 12}
    \]
    or around $23\%$.
\end{example}

\subsection{The Prosecutor's Fallacy}
Sally Clark was a British woman who lost both of her two children (apparently) to SIDS the late 1990s. This raised suspicion leading her to be tried for murder. The prosecution's case hinged on Sir Roy Meadows' argument that SIDS is very rare, only affecting around 1 in every 8500 children. Therefore the probability of two children dying of SIDS $(1/8500)^2$. In other words, there is a $99.9999986\%$ chance that she is guilty, which clearly goes beyond any reasonable doubt one could have, and so the jury convicted her (though this conviction was later overturned). There are two issues with Meadows' argument:
First of all, the it assumes that the two deaths are are Independent Events. But are they? Perhaps there is a genetic component to SIDS which both children had, or something in the shared environment. Hence the probability of two children in the same family dying may not be all that much higher than the probability of just one. This is an important point, however on its own it does little do dispel the evidence against Mrs. Clark, since even the probability of only one child dying is rather low. In fact, had the courts tried Mrs. Clark after her only her first child, they could have made a similar argument and claimed there was a $99.988\%$ chance she was guilty based on that alone. So then by this logic, should all cases of SIDS be treated not only with suspicion but as outright proof of fowl play? Clearly this would be preposterous, and it is here we begin to really see the cracks in the Meadows' argument.
\\\\
Let $E$ be the probability of having two children die of SIDS, and let $I$ be the probability of the mother being innocent. If we do assume that each child dying is an Independent Event, then it is true that $P(E|I)=1/8500^2$. However, Meadows claim conflated this with $P(I|E)$. These quantities are not necessarily equal, however they are related, so it is worth asking: what \emph{can} we learn about $P(I|E)$ from $P(E|I)$. Using Bayes Rule, 
\[
    P(I|E)=\frac{P(E|I)P(I)}{P(E)}=\frac 1 {72\,250\,000}\times \frac{P(I)}{P(E)}
\]

\todo finish????

\todo https://forensicstats.org/blog/2018/02/16/misuse-statistics-courtroom-sally-clark-case/

\section{Statistical Independence}
\subsection{Two Events}
Two Events $A$ and $B$ are \textbf{Independent} if they do not have any ``information" about the other. In other words knowing that $B$ has occurred does not change the probability of $A$ having occurred. We can express this symbolically as follows
\[
    P(A|B)=P(A)
\]
or equivalently:
\[
    P(A\cap B)=P(A)P(B)
\]
\begin{notsofast}
    Independence is \emph{not} the same as Mutual Exclusivity. In fact if $A$ and $B$ are Mutually Exclusive then they cannot be independent. 
    \begin{proof}
        Suppose $A$ and $B$ are two Mutually Exclusive Events and we know that $B$ has occurred. Then we also know $A$ must not have occurred. In other words, knowing $B$ has occurred has given us information about the probability of $A$ (namely that the probability is zero). 
    \end{proof}
\end{notsofast}

\begin{lemma}
Let $A$ and $B$ be Independent Events. Then the following pairs are also Independent:
\begin{enumerate}
    \item[i.] $A$ and $\bar B$
    \item[ii.] $\bar A$ and $B$
    \item[iii.] $\bar A$ and $\bar B$
\end{enumerate}
\tcblower
\begin{proof}
    \begin{enumerate}
        \item[]
        \item[i.] 
        \item[ii.] 
        \item[iii.] 
    \end{enumerate}
\end{proof}
\end{lemma}

\subsection{More than two Events}

\subsection{Conditional Independence}


Two events are \textbf{Conditionally Independent} given $C$ if 
\[
    P(A\cap B | C)= P(A|C)P(B|C)
\]

\todo

\newpage








\section{Simpson's Paradox}
Let us return to one of the problems we considered at the end of \ref{sec:problaw_eosp}: Suppose we have two doctors (we will call them Bart and Lisa) each performing two operations (for instance: neurosurgery and bandaging a wound). Both doctors perform each surgery with some success rate. Now here's the riddle: is it possible that Dr. Lisa is better than Dr. Bart at both neurosurgery and bandaging, and yet have a lower overall success-rate? Counter-intuitively, the answer is ``yes". How is this possible? Well consider the following data set:
\vspace{15px}
\begin{center}
Dr. Lisa (total success rate: 80\%)\\
\vspace{5px}
\begin{tabular}{c|cc }
& \textbf{Neurosurgery} & \textbf{Bandaging} \\ 
\hline
\textbf{Successes} & 70 & 10 \\  
\textbf{Failures} & 20 & 0 \\
\hline
\textbf{Success Rate} & 78\% & 100\% 
\end{tabular}
\end{center}

\vspace{15px}
\begin{center}
Dr. Bart (total success rate: 83\%)\\
\vspace{5px}
\begin{tabular}{c|cc}
&\textbf{Neurosurgery} & \textbf{Bandaging} \\ 
\hline
\textbf{Successes} & 2 & 81 \\  
\textbf{Failures} & 8 & 9 \\
\hline
\textbf{Success Rate} & 20\% & 90\% 
\end{tabular}
\vspace{15px}
\end{center}

The lesson here is that sometimes if we just add up the totals and don't account for confounding variables, our results will be misleading. If you were to choose one of these doctors based on their overall success rate alone, you might choose Dr. Bart, despite the fact that Dr. Lisa is clearly a better doctor. This phenomenon is known as Simpson's paradox, named not after the hit television series but rather British statistician Edward H. Simpson who first described it in 1951 (\todo http://math.bme.hu/~marib/bsmeur/simpson.pdf). And since then, there have been many cases of analysts falling victim to it.

\subsection{Batting averages}
\todo One of the things that matters in baseball is a players batting average -- i.e. the proportion of times that a batter is successful. 300 means 30\%, which is very very good. Derek Jeter and David Justice. In 1995 and 1996 Justice has a better average than Jeter (CONFIRM). However if you just add them up, 
??????????????
\subsection{Racism on death row}
\todo Florida looked at all convicted murderers, and looked at what proportion were sentanced to death. They wanted to see if black people were sentenced to death more often then white people. Was there discrimination. Is there discrimination when it comes to the death penalty? They found that white defindents got sentenced to death 11\% of the time, but blakc people only got sent to death 7.9\% of the time. So this would seem to oppose the hypothesis. In fact, it seems that white people are being sent to death far more often. 

However lets look a little more deeply into the data and look at the victim's race, where you can see that this is really what matters. ???? Black people murder more black people, white people murder more white people, and those who murder white people get the death penalty more often. 

This is called a confounding variable







\section{The Secretary Problem}
Suppose you have applied to three jobs and are waiting to hear back. You are pretty sure that all three companies will give you an offer, but you do not know what salary they will offer you. And after each company presents their offer, you will have to decide whether to accept or reject it, and will not have time wait around to see what the next company is planning to offer you. What is the optimal strategy for maximizing your chances of accepting the best offer?
\\\\ 
As it turns out, the best strategy is to reject the first regardless of what they offer, and then accept any offer better than that. To illustrate this, let us suppose we have three companies $A$ (best offer), $B$ (second-best offer), and $C$ (worst offer). There are $3!=6$ orders in which they may call you. We will assume that all orders are equally likely, and consider what happens in each scenario:
\\\\
\allowdisplaybreaks
\begin{tabularx}{325pt}{cXc}

1.\ \textbf{ABC:} 
&
So far, our strategy is not off to a great start. We reject $A$ and are left disappointed by the remaining two offers. 
&
\raisebox{-0.75\height}{\includesvg[width=25px]{symbols/xcheck-red-x.svg}}
\\\\
2.\ \textbf{BAC:} 
&
This works out better a bit better. We reject $B$ and and then get the better offer $A$, which turns out to be the best.
&
\raisebox{-0.75\height}{\includesvg[width=25px]{symbols/xcheck-green-check.svg}}
\\\\
3.\ \textbf{BCA:} 
&
Here we reject $B$ and then $C$, and finally accept the best offer $A$.
&
\raisebox{-0.75\height}{\includesvg[width=25px]{symbols/xcheck-green-check.svg}}
\\\\
4.\ \textbf{CBA:} 
&
Here we do a little worse. By starting with $C$ we end up setting our standards too low and accept $B$ instead of holding out for the better offer
&
\raisebox{-0.75\height}{\includesvg[width=25px]{symbols/xcheck-red-x.svg}}
\\\\

5.\ \textbf{CAB:} 
&
But here, those low standards don't end up mattering, since the best offer happens to be the very next one.
&
\raisebox{-0.75\height}{\includesvg[width=25px]{symbols/xcheck-green-check.svg}}
\\\\

6.\ \textbf{ACB:} 
&
And once again, we end up the same problem we encountered in the first round, setting our standards too high and missing out on our best offer.
&
\raisebox{-0.75\height}{\includesvg[width=25px]{symbols/xcheck-red-x.svg}}

\end{tabularx}
\\\\

All in all, we end up getting the best offer half of the time.

\todo JUSTIFY THE GENERALIZATION

However let's generalize this this to $n$ people. (Answer $\nicefrac 1e$). This is often known as the 37\% rule. 


\section{Discrete Random Variables}
A \textbf{Discrete Random Variable} (DRV) $X$ is a function which map Events to integers. For instance, it could represent the face of a die we roll, or the number of heads we get flipping two coins. There is little in the way of properties which a DRV must satisfy, and it is perfectly possible for them to return negative integers as well as positive ones. For instance, if we measure the difference between the face of two dice or the total profits made from playing a casino game. We should however be able to define either a \textbf{Probability Mass Function} to a \textbf{Cumulative Distribution Function}

\subsection{Probability Mass Function}
Probability Mass Functions (PMFs) describe the probability of observing a given realization $x$ of a DRV $X$, and are often represented as either $P(X=x)$ or $f(x)$. We may define them in any way so long as they satisfy the following properties:
\begin{enumerate}
    \item For all $x\in \mathbb Z$, $f(x)\ge 0$
    \item $\displaystyle\sum_{x\in\mathbb Z} f(x)=1$
\end{enumerate}
Often PMFs are expressed with a table listing $(x, f(x))$ for all $x$-values such that $f(x)\ne 0$.

\begin{example}{Flipping Coins}
    Suppose we toss a (fair) coin twice and let $X$ be a Random Variable representing the number of heads we observe. Define a PMF which describes this situation and show that it satisfies the necessary properties.
\tcblower
We may use
    \[
        \begin{array}{c|c}
            x & f(x) \\
            \hline
            0 & (\nicefrac 12)^2 \\
            1 & 2(\nicefrac 12)^2 \\
            2 & (\nicefrac 12)^2 
        \end{array}
    \]
We can see that $f(x)\ge 0$ for all values shown (and equal to zero for all values omitted), thus it satisfies Property 1. If we add the values up we see
\[
    \sum_{x\in\mathbb Z}f(x)=\frac 14 + \frac 12 + \frac 14 = 1
\]
\end{example}
\begin{notsofast}
    Do not confuse DRVs with their distributions! For instance, it is sometimes mistakenly assumed that the PMF of $2X$ is simply $2f(x)$. However this is not the case, and it is not even possible for $2f(x)$ to be \emph a PMF in the first place, let alone the PMF which correctly describes $2X$. Transforming DRVs is not so simple.
    \\\\
    For another common mistake, consider two DRVs $X$ and $Y$ which both have the same PMF. Are $X$ and $Y$ equal? Absolutely not! In fact, it may not even be possible to observe the same value from each of them at the same time. For a concrete example of this, suppose we flip three coins and let $X$ be the number of heads we observe, and let $Y$ be the number of tails we observe. Then the PMFs for $X$ and $Y$ are as follows:
    \[
        \begin{array}{ccc}
            \begin{array}{c|c}
                x & f(x) \\
                \hline
                0 & \nicefrac 18 \\
                1 & \nicefrac 38 \\
                2 & \nicefrac 38 \\
                3 & \nicefrac 18
            \end{array}
            & \hspace{100px} &
            \begin{array}{c|c}
                y & f(y) \\
                \hline
                0 & \nicefrac 18 \\
                1 & \nicefrac 38 \\
                2 & \nicefrac 38 \\
                3 & \nicefrac 18
            \end{array}
        \end{array}
    \]
    Yet there is no scenario in which we can flip three coins and get the same number of heads as tails.
    \begin{proof}
        Since all coins must be either heads or tails, $x+y=3$. Suppose that $x=y$. Then we may write $2x=3$ and therefore $x$ (and by extension $y$) must not be an integer, which contradicts the real-world interpretation of $x$ and $y$.
    \end{proof}
\end{notsofast}

\subsection{The Cumulative Distribution Function}
Another way we can describe a Random Variable is using the Cumulative Distribution Function (CDF), often represented by $F(x)$. This describes, not the probability of observing $x$, but rather the probability of observing some value less than or equal to $x$. CDFs must satisfy the following properties:
\begin{enumerate}
    \item For all $x\in\mathbb Z$, $0\le F(x) \le 1$
    \item $F$ must be nondecreasing. In other words for any $x,y\in\mathbb Z$ such that $x<y$, $F(x)\le F(y)$
    \item For \emph{Discrete} Random Variables (we will discuss Continuous Random Variables in the next section) the $F$ is a step function
    \item $F$ is right continuous
\end{enumerate}
\todo

It is possible to determine the CDF from the PMF and vice versa using the following relation
\begin{lemma}
    \[
        f(x)=F(x)-F(x-1)
    \]
\end{lemma}\label{lem:cdf2pmf}


\begin{example}{PMF v. CDF}
    Suppose you roll 4 dice and let $X_i$ be the face of the $i$th die. Then let $X=\max\{X_1, X_2, X_3, X_4\}$. Find the PMF of $X$
\tcblower
\subsubsection{The Bad Way}
$X$ will return some value between 1 and 6 inclusive. For the maximum to be a $1$, we must have $X_1=X_2=X_3=X_4=1$, which has a probability of $(\nicefrac 1 6)^4$. Then the probability of the maximum being 2 is given by the probability that one of the 4 is 2 and the rest are either 1 or 2. Determining the probability of this Event would be tedious to calculate, and 3 4 and 5 will be just as tedious, so we will stop here hoping we have sufficiently made the point that this is a bad way to determine the PMF.

\subsubsection{The Good Way}
The CDF of $X_i$ for $i=1,2,3,4$ is
\[
    P(X_i\le x)=\frac x 6
\]
for all $x=1,2,...,6$ (for all other $x$-values it is zero) Then $X$ will return a value less than or equal to $x=1,2,...,6$ if and only if $X_1, X_2,X_3,X_4$ all return values less than or equal to $x$. Thus
\[
    P(X\le x)=\prod_{i=1}^4 P(X_i\le x)=\left(\frac x 6\right)^4
\]
Then using Lemma \ref{lem:cdf2pmf} we get
\[
    P(X=x)= \left(\frac x 6\right)^4-\left(\frac {x-1} 6\right)^4
\]
\end{example}



\subsection{Expectation}
\newcommand{\E}{\text E}
The \textbf{Expectation} of a Random Variable describes where the average observation of a Random Variable will tend towards when repeated many many times.
\begin{definition}{Expectation of a DRV}
Let $X$ be a DRV with PMF $f$. Then
    \[
        E(X)=\sum_{x\in\mathbb Z} x f(x)
    \]
    
\end{definition}
\begin{theorem}{Properties of Expectation}
    Let $X$ and $Y$ be two DRVs
    \begin{enumerate}
        \item $E(X+Y)=E(X)+E(Y)$
        \item For any transformation $g:\mathbb R\to\mathbb R$
        \[
            E\left[g(X)\right] = \sum_{x\in \mathbb Z} P(X=x) g(x)
        \]
    \end{enumerate}
\tcblower
    The proof of the first property may seem relatively straightforward. However it is trickier than one might expect, especially since it applies even when $X$ and $Y$ are Dependent. We will come back to it later.
    \todo PROOF OF SECOND
\end{theorem}

\begin{example}{Expectation of a transformed DRV}
    Find $E(X^2)$ where
    \[
        \begin{array}{c|c}
             x & f(x) \\
             \hline
             -1 & \nicefrac 13\\
             0 & \nicefrac 13 \\
             1 & \nicefrac 13
        \end{array}
    \]
\tcblower
    \subsubsection*{The Bad Way}
    Let $Y=X^2$. Then the PMF of $Y$ is as follows
    \[
        \begin{array}{c|c}
             y & f(y) \\
             \hline
             0 & \nicefrac 13 \\
             1 & \nicefrac 13 + \nicefrac 13
        \end{array}
    \]
    Then 
    \[
        \E(Y)=\frac 23
    \]
    \subsubsection*{The Good Way}
    \[
        E(X^2)=(-1)^2\times \frac 13 + 0^2\times \frac 13 + 1^2 \frac 13 = \frac 13
    \]
\end{example}

\subsection{The St. Petersberg Paradox}
There was ostensibly once a casino in St. Petersberg which offered a certain coin-flipping game. For some relatively large ticket-price, you could flip a coin. If the coin lands on heads, you would get your payout (starting out at a value much smaller than the ticket price). On the other hand, if the coin landed tails you got another flip with the payout doubled. The game could go on and on like this until the coin hits heads.
\begin{example}{The St. Petersberg Paradox}
    Calculate the Expected payout for the coin flip game of the St. Petersberg paradox, assuming that the initial payout is $\$2$.
\tcblower
    Let $X$ be the payout received from playing the coin game. Then the PMF of $X$ is
    \[
        \begin{array}{c|c}
             x & f(x) \\
             \hline
             2 & \nicefrac 12 \\
             4 & \nicefrac 14 \\
             16 & \nicefrac 1{16} \\
             \vdots & \vdots
        \end{array}
    \]
    From this we get
    \[
        E(X) = 2\times \frac 12 + 4 \times \frac 1 4 + \cdots = \infty
    \]
\end{example}
Thus this would not seem to be a particularly profitable game for a casino to run, since no matter what ticket price we set, the casino would in theory always lose money. So suppose we set a ticket price of $\$50$. Would playing be a good idea? Well, though the Expectation is technically infinite, we only have a 1 in 64 chance of actually winning any money. In other words, we could easily find ourselves over $\$3000$ in debt before seeing any winnings.  So clearly Expectation is not everything. This brings us to \textbf{Variance}.

\subsection{Variance}
\newcommand{\Var}{\text{Var}}
The Variance of a DRV is the average of the squared deviation from the mean. In other words
\begin{definition}{Variance of a DRV}
    Let $X$ be a DRV 
    \[
        \Var(X)=E[(X-E(X))^2]   
    \]
    However this is not the most convenient formula to work with. More often we can use the equivalent formula
    \[
        \Var(X)=E(X^2)-[E(X)]^2
    \]
\end{definition}


\begin{theorem}{Properties of the Variance}
    Suppose $X$ and $Y$ are two Independent Random Variable, and $a$ and $b$ are constants
    \begin{enumerate}
        \item $\Var(a)=0$
        \item $\Var(aX+b)=a^2\Var(X)$
        \item $\Var(X+Y)=\Var(X)+\Var(Y)$
    \end{enumerate}
\end{theorem}

\begin{notsofast}
    The above Property 3 only applies if $X$ and $Y$ are Independent. For Dependent Random Variables, there are different rules.
\end{notsofast}


\subsection*{End-of-the-section Problems}
\begin{enumerate}
    \item Prove the linearity property of Expectation
    \item Show that $E[(X-E(X))^2]=E(X^2)-[E(X)]^2$
\end{enumerate}

\section{Named Distributions for DRVs}
\subsection{The Bernoulli Distribution}
Let $X$ be some $p\in[0,1]$ and consider some DRV with the following PMF
\[
    \begin{array}{c|c}
         x & f(x) \\
         \hline
         0 & 1-p \\
         1 & p
    \end{array}
\]
This is a valid PMF since $(1-p)+p=1$. It is a very simple distribution, but an important one none the less -- important enough to warrant a name: \textbf{The Bernoulli Distribution}. 


\newpage


The \textbf{Bernoulli Distribution} takes one parameter $p\in[0,1]$ and has the following P.M.F:
\[
    \todo
\]

This is a very simple distribution, and perhaps feels almmost not worth learning. However it is the building block for many other distributions as well as indicator variables which we will dicuss later???? \todo CONFIRM???


\section{Continuous Random Variables}

\chapter{Multivariate and Conditional Distributions}

\chapter{Stochastic Process}



\end{document}
